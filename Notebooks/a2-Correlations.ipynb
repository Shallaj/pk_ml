{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbcf6d0722b4332d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Correlations\n",
    "\n",
    "This notebook will demonstrate the strengths of weaknesses of correlations, and especially inferring causation from them.\n",
    "\n",
    "## Tips & Tricks\n",
    "\n",
    "The following are a couple tips & tricks that may help you if you get stuck on anything.\n",
    "\n",
    "#### Printing Variables\n",
    "You can (and should) print and check variables as you go. This allows you to check what values they hold, and fix things if anything unexpected happens.\n",
    "\n",
    "#### Restarting the Kernel\n",
    "- If you run cells out of order, you can end up overwriting things in your namespace. \n",
    "- If things seem to go weird, a good first step is to restart the kernel, which you can do from the kernel menu above.\n",
    "- Even if everything seems to be working, it's a nice check to 'Restart & Run All', to make sure everything runs properly in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic plotting imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # high res plotting\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a80f9f3295cb2ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Correlation basics\n",
    "\n",
    "This section serves as a reminder for the basics of how correlation works. A Pearson correlation is a normalized measure of the covariance between two variables (features); more simply, it quantifies how linear the relationship is between the two variables.\n",
    "\n",
    "Below, we will walk you through the powers, pitfalls, and idiosyncrasies of correlations.\n",
    "\n",
    "\n",
    "## Question 1: Random data\n",
    "\n",
    "To begin, use numpy.random.normal to create two normally distrubted random variables: <code>random_data1 and random_data2</code>\n",
    "\n",
    "<code>random_data1</code> should have mean=1.0, std=1.0\n",
    "<code>random_data2</code> should have mean=6.0, std=2.5\n",
    "\n",
    "Both should have 1000 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1f5c27f99bc71e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "number_of_samples = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-233c9bf7b5b03e69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Random data correlation significance\n",
    "\n",
    "Now let's look at the Pearson correlation between the two random datasets.\n",
    "\n",
    "But first, given that these are two random variables, will they be correlated?\n",
    "\n",
    "* `A`: They will <em>definitely</em> be significantly correlated (<em>p</em> < 0.05)\n",
    "* `B`: They will <em>definitely not</em> be significantly correlated (<em>p</em> > 0.05) \n",
    "* `C`: The correlation between them cannot be assessed\n",
    "* `D`: The correlation will probably be non-significant (<em>p</em> > 0.05) but will sometimes be significant (<em>p</em> < 0.05)\n",
    "\n",
    "Write your answer below as a new variable, <code>q2_answer</code>. So if the answer was a hypothetical option <code>E</code>, you would write:\n",
    "\n",
    "<code>q2_answer = 'E'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a742e3f3895f1fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e18c7438bdf22a7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3: Correlating random data\n",
    "\n",
    "Now let's look at the actual Pearson correlation.\n",
    "\n",
    "To do this, call <code>scipy.stats.pearsonr</code> and store the Pearson correlation coefficient as <code>r_random</code> and the associated <em>p</em>-value as <code>p_random</code>.\n",
    "\n",
    "Then plot the relationship with <code>random_data1</code> as the x-axis and <code>random_data2</code> as the y-axis. Set the opacity (alpha) of the points equal to 0.5, by defining a new variable, <code>alpha_scatter</code> and calling that in the scatterplot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d446a4f129f5e0f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-974af09e3abac364",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4: Making a linear correlation\n",
    "\n",
    "Okay, so  we know that a Pearson correlation quatifies how linear the relationship is between two variables (features).\n",
    "\n",
    "Now, let's create a new variable, <code>correlated_data1</code>, that is explicitly a linear function of <code>random_data1</code>, plus some noise.\n",
    "\n",
    "To do this, set <code>correlated_data1</code> equal to <code>random_data1</code> plus 20., and add normally-distributed noise of mean=0., std=0.5\n",
    "\n",
    "Calculate the Pearson correlation coefficient between them as <code>r_corr</code> and the associated <em>p</em>-value as <code>p_corr</code>.\n",
    "\n",
    "Plot the results using the same opacity as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f056a5ab429c813",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a8f224208708e66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Correlation cautions\n",
    "\n",
    "\n",
    "## Q5: Assessing correlation significance\n",
    "\n",
    "Now we're going to switch gears and give you four sets of data:\n",
    "\n",
    "* <code>(x1, y1)</code>\n",
    "* <code>(x2, y2)</code>\n",
    "* <code>(x3, y3)</code>\n",
    "* <code>(x4, y4)</code>\n",
    "\n",
    "Calculate the means and variances for each of the eight variables.\n",
    "\n",
    "To do this, make a list of the <code>x</code> variables, called <code>xs</code>; do the same for the <code>y</code> variables, called <code>ys</code>.\n",
    "\n",
    "Then create a variable called <code>x_stats</code> that has two arrays: the means for each <code>x</code> variable, and the vars for each <code>x</code> variable; do the same for the <code>y</code> variables, called <code>y_stats</code>\n",
    "\n",
    "Calculate the Pearson correlation coefficients and the associated <em>p</em>-values. Store the correlation coefficients as an array called <code>rs</code>, and the <em>p</em>-values as an array called <code>ps</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7acaaf57f7bb9d97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Given arrays (don't change these!)\n",
    "x1 = np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5])\n",
    "y1 = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "x2 = np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5])\n",
    "y2 = np.array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
    "x3 = np.array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5])\n",
    "y3 = np.array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
    "x4 = np.array([8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8])\n",
    "y4 = np.array([6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89])\n",
    "\n",
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5828fa5c6e373d98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q6: Interpreting these results\n",
    "\n",
    "Okay, so given the means, variances, and Pearson correlation coefficients (collectively, \"summary statistics\") for the four above datasets, what inference do you make about them?\n",
    "\n",
    "* `A`: The summary statistics are all very close to the same\n",
    "* `B`: The means and variances are close to the same, but the Pearson correlations are different\n",
    "* `C`: The means and variances are very different, but the Pearson correlations are very similar\n",
    "* `D`: All the summary statistics are very different from one another\n",
    "\n",
    "Write your answer below as a new variable, <code>q6_answer</code>. So if the answer was a hypothetical option <code>E</code>, you would write:\n",
    "\n",
    "<code>q6_answer = 'E'</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee491b37d9d163d4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a55e2346d3ff2bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q7: Summary statistics: a cautionary tale\n",
    "\n",
    "Now plot the four <code>(x, y)</code> pairs. What inference do you make about them, now?\n",
    "\n",
    "* `A`: The <code>(x, y)</code> pairs all look very similar\n",
    "* `B`: The <code>(x, y)</code> pairs all look linear\n",
    "* `C`: The <code>(x, y)</code> pairs all look very different\n",
    "* `D`: The <code>(x, y)</code> pairs all look quadratic\n",
    "\n",
    "Write your answer below as a new variable, <code>q7_answer</code>. So if the answer was a hypothetical option <code>E</code>, you would write:\n",
    "\n",
    "<code>q7_answer = 'E'</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b0242660c36fe0b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba94ac01e332a19d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q8: Alternative correlation approaches\n",
    "\n",
    "Having plot the data, you may have noticed certain features that might lead the Pearson correlation to return results that don't match with your intuitive relationship between the variables.\n",
    "\n",
    "Let's figure out some ways of addressing that.\n",
    "\n",
    "We're going to create two variables. The first, <code>x_axis</code>, is supplied below. It is simply 10 numbers, evenly spaced, between 1 and 100.\n",
    "\n",
    "The second should be a function of <code>x_axis</code>. Specifically, create a new variable, <code>nonlinear_data</code> that is <code>x_axis</code> divided by <code>x_axis**2</code>. Plot the results.\n",
    "\n",
    "Last, calculate the Pearson correlation and associated <em>p</em>-value as <code>r_nonlinear</code> and <code>p_nonlinear</code>, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed2a867c0bd42af4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_axis = np.linspace(1, 100, 10)\n",
    "\n",
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ac6bdeb93c03e6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q9: Summary statistics: a cautionary tale\n",
    "\n",
    "From the plot above (and from the equation), you can see that <code>nonlinear_data</code> is monotonically related to <code>x_axis</code>, such that each successive value of <code>nonlinear_data</code> is smaller than the previous. But the <em>p</em>-value from the Pearson correlation significance test is non-significant (<em>p</em> > 0.05).\n",
    "\n",
    "A non-parameteric alternative to the Pearson correlation is the Spearman correlation (<code>scipy.stats.spearmanr</code>). This correlation approach examines the monotonicity of the relationship between the two variables. That is, rather than asking if they're linearly related, it asks how much one variable regularly increases (or decreases) in relation to the other.\n",
    "\n",
    "For this question, calculate the Spearman correlation between <code>x_axis</code> and <code>nonlinear_data</code>, and the associated <em>p</em>-value, as <code>rho_nonlinear</code> and <code>pho_nonlinear</code>, respectively.\n",
    "\n",
    "Do the same for all <code>(x, y)</code> pairs above. Store the correlation coefficients as an array called <code>rho_spearman</code>, and the <em>p</em>-values as an array called <code>p_spearman</code>.\n",
    "\n",
    "Note how the Spearman correlation coefficiencts ($\\rho$) and <em>p</em>-values differ from the Pearson ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f0bf1f90dfa785ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e98b6d2ba0f7a2b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q10: Model testing: Nonlinear models\n",
    "\n",
    "Okay so now what do we do with this? Some of those <code>(x, y)</code> pairs above look like they have clear relationships (nonlinear, or linear with outliers). How do we handle this kind of thing?\n",
    "\n",
    "Here we're going to do a little basic model testing using <code>scipy.optimize.curve_fit</code>. This function lets us define any function of the form:\n",
    "\n",
    "$$ y = f(x) $$\n",
    "\n",
    "In the cell below I show how you define a linear function:\n",
    "\n",
    "$$ y = ax + b $$\n",
    "\n",
    "pass that into <code>scipy.optimize.curve_fit</code>, and plot the fit.\n",
    "\n",
    "You job is to write another function, <code>quadratic_func</code>:\n",
    "\n",
    "$$ y = ax^2 + bx + c $$\n",
    "\n",
    "and calculate both the linear and quadratic $R^2$ fits for all of the <code>(x, y)</code> pairs. I've provided the $R^2$ function, <code>fit_r2</code>, for you.\n",
    "\n",
    "Store the linear $R^2$ fits as an array called <code>linear_r2</code> and the quadratic as <code>quadratic_r2</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd692b604a366d35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def linear_func(x, a, b):\n",
    "    return (a * x) + b\n",
    "\n",
    "def fit_r2(ydata, yfit):\n",
    "    residuals = ydata - yfit # difference between data and fit\n",
    "    ss_res = np.sum(residuals**2) # sum of the squares (ss) of the residuals\n",
    "    ss_tot = np.sum((ydata - np.mean(ydata))**2) # total sum of squares\n",
    "    r2 = 1 - (ss_res / ss_tot) # r-squared    \n",
    "    return r2\n",
    "\n",
    "xdata = xs[0,:]\n",
    "ydata = ys[0,:]\n",
    "popt, _ = curve_fit(linear_func, xdata, ydata)\n",
    "yfit = linear_func(xdata, *popt)\n",
    "\n",
    "# Because it can be non-intuitive, the below code will plot\n",
    "# your data and the fits, so you can test your code out\n",
    "#\n",
    "# indices = np.argsort(xdata)\n",
    "# yfit_sorted = yfit[indices]\n",
    "# xfit_sorted = xdata[indices]\n",
    "# plt.plot(xdata, ydata, 'o', label='data')\n",
    "# plt.plot(xfit_sorted, yfit_sorted, '--', label='fit')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b0d84768cc7c1e66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q11: Model testing: Resampling\n",
    "\n",
    "You'll see that the quadratic fit dramatically improves the fit quality for one of the <code>(x, y)</code> pairs, but doesn't do much for the others. So another way to test model fits is by using a broad class of resampling methods. In this approach, instead of fitting all of your data, you select a random segemnt of your data, fit those points and store the fit results, draw another random sample, fit those points and store the results, and so on.\n",
    "\n",
    "Here, I want you to calculate the $R^2$ linear and quadratic fits for <em>all but one</em> data point for each of the four <code>(x, y)</code> pairs. That is, for each <code>(x, y)</code> pairs, fit everything except the zeroth element (so <code>xs[:, 1:]</code>). Then iterate by fitting all points except the first element, and then iterate again for all but the second, and so on.\n",
    "\n",
    "Store the resampled linear $R^2$ fits as a <code>(4, 11)</code> array called <code>resampled_linear_r2</code> and the quadratic as an array of the same size called <code>resampled_quadratic_r2</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38ce5f100b5276f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4cab9b89f1a3701",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Final takeaways\n",
    "\n",
    "Look at the distribution of possible correlation coefficients that your data can take. For example, one of the <code>(x, y)</code> looks like a clear linear fit with a single large outlier; in that case, the distribution of correlation coefficients all look similar, except for a single case where the $R^2$ is nearly equal to 1.0. Similarly, another of the pairs looks like a perfect quadratic fit in every single resampling scenario.\n",
    "\n",
    "What you do, as a scientist, with this information, is part of the \"art\" of the data analysis decision making process!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
